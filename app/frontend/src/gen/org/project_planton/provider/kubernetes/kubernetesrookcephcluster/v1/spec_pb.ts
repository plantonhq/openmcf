// @generated by protoc-gen-es v2.2.2 with parameter "target=ts"
// @generated from file org/openmcf/provider/kubernetes/kubernetesrookcephcluster/v1/spec.proto (package org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1, syntax proto3)
/* eslint-disable */

import type { GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import { file_buf_validate_validate } from "../../../../../../buf/validate/validate_pb";
import type { ContainerResources } from "../../kubernetes_pb";
import { file_org_openmcf_provider_kubernetes_kubernetes } from "../../kubernetes_pb";
import type { KubernetesClusterSelector } from "../../target_cluster_pb";
import { file_org_openmcf_provider_kubernetes_target_cluster } from "../../target_cluster_pb";
import type { StringValueOrRef } from "../../../../shared/foreignkey/v1/foreign_key_pb";
import { file_org_openmcf_shared_foreignkey_v1_foreign_key } from "../../../../shared/foreignkey/v1/foreign_key_pb";
import { file_org_openmcf_shared_options_options } from "../../../../shared/options/options_pb";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file org/openmcf/provider/kubernetes/kubernetesrookcephcluster/v1/spec.proto.
 */
export const file_org_openmcf_provider_kubernetes_kubernetesrookcephcluster_v1_spec: GenFile = /*@__PURE__*/
  fileDesc("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", [file_buf_validate_validate, file_org_openmcf_provider_kubernetes_kubernetes, file_org_openmcf_provider_kubernetes_target_cluster, file_org_openmcf_shared_foreignkey_v1_foreign_key, file_org_openmcf_shared_options_options]);

/**
 * KubernetesRookCephClusterSpec defines the configuration for deploying a Rook Ceph storage cluster on Kubernetes.
 * The Rook Ceph Operator must be installed before deploying this resource.
 * This component creates a CephCluster along with optional block pools, filesystems, and object stores.
 *
 * @generated from message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.KubernetesRookCephClusterSpec
 */
export type KubernetesRookCephClusterSpec = Message<"org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.KubernetesRookCephClusterSpec"> & {
  /**
   * Target Kubernetes Cluster where the Ceph cluster will be deployed.
   *
   * @generated from field: org.openmcf.provider.kubernetes.KubernetesClusterSelector target_cluster = 1;
   */
  targetCluster?: KubernetesClusterSelector;

  /**
   * Kubernetes Namespace where the Ceph cluster will be installed.
   * This namespace should match or be different from the operator namespace depending on your multi-tenancy requirements.
   * Default: rook-ceph
   *
   * @generated from field: org.openmcf.shared.foreignkey.v1.StringValueOrRef namespace = 2;
   */
  namespace?: StringValueOrRef;

  /**
   * Flag to indicate if the namespace should be created if it does not exist.
   * Default: true
   *
   * @generated from field: optional bool create_namespace = 3;
   */
  createNamespace?: boolean;

  /**
   * Namespace where the Rook Ceph Operator is installed.
   * Default: rook-ceph
   *
   * @generated from field: optional string operator_namespace = 4;
   */
  operatorNamespace?: string;

  /**
   * The version of the Rook Ceph Cluster Helm chart to deploy.
   * https://github.com/rook/rook/releases
   * Default: v1.16.6
   *
   * @generated from field: optional string helm_chart_version = 5;
   */
  helmChartVersion?: string;

  /**
   * Ceph container image configuration.
   *
   * @generated from field: org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephImageSpec ceph_image = 6;
   */
  cephImage?: CephImageSpec;

  /**
   * Core Ceph cluster configuration.
   *
   * @generated from field: org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephClusterConfig cluster = 7;
   */
  cluster?: CephClusterConfig;

  /**
   * Block storage pool configuration.
   * Block pools provide RBD (RADOS Block Device) storage for persistent volumes.
   *
   * @generated from field: repeated org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephBlockPoolSpec block_pools = 8;
   */
  blockPools: CephBlockPoolSpec[];

  /**
   * Filesystem configuration for CephFS.
   * CephFS provides POSIX-compliant shared filesystem storage.
   *
   * @generated from field: repeated org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephFilesystemSpec filesystems = 9;
   */
  filesystems: CephFilesystemSpec[];

  /**
   * Object store configuration for S3-compatible storage.
   * Object stores provide Ceph RADOS Gateway (RGW) for S3/Swift API access.
   *
   * @generated from field: repeated org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephObjectStoreSpec object_stores = 10;
   */
  objectStores: CephObjectStoreSpec[];

  /**
   * Enable the Ceph toolbox deployment for debugging.
   * Default: false
   *
   * @generated from field: optional bool enable_toolbox = 11;
   */
  enableToolbox?: boolean;

  /**
   * Enable Prometheus monitoring integration.
   * Default: false
   *
   * @generated from field: optional bool enable_monitoring = 12;
   */
  enableMonitoring?: boolean;

  /**
   * Enable Ceph dashboard for web-based cluster management.
   * Default: true
   *
   * @generated from field: optional bool enable_dashboard = 13;
   */
  enableDashboard?: boolean;
};

/**
 * Describes the message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.KubernetesRookCephClusterSpec.
 * Use `create(KubernetesRookCephClusterSpecSchema)` to create a new message.
 */
export const KubernetesRookCephClusterSpecSchema: GenMessage<KubernetesRookCephClusterSpec> = /*@__PURE__*/
  messageDesc(file_org_openmcf_provider_kubernetes_kubernetesrookcephcluster_v1_spec, 0);

/**
 * CephImageSpec defines the Ceph container image configuration.
 *
 * @generated from message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephImageSpec
 */
export type CephImageSpec = Message<"org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephImageSpec"> & {
  /**
   * Container image repository.
   * Default: quay.io/ceph/ceph
   *
   * @generated from field: optional string repository = 1;
   */
  repository?: string;

  /**
   * Container image tag.
   * Default: v19.2.3
   *
   * @generated from field: optional string tag = 2;
   */
  tag?: string;

  /**
   * Allow unsupported Ceph versions. Not recommended for production.
   * Default: false
   *
   * @generated from field: optional bool allow_unsupported = 3;
   */
  allowUnsupported?: boolean;
};

/**
 * Describes the message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephImageSpec.
 * Use `create(CephImageSpecSchema)` to create a new message.
 */
export const CephImageSpecSchema: GenMessage<CephImageSpec> = /*@__PURE__*/
  messageDesc(file_org_openmcf_provider_kubernetes_kubernetesrookcephcluster_v1_spec, 1);

/**
 * CephClusterConfig defines the core Ceph cluster settings.
 *
 * @generated from message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephClusterConfig
 */
export type CephClusterConfig = Message<"org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephClusterConfig"> & {
  /**
   * The path on the host where Ceph configuration files will be persisted.
   * Must be unique if running multiple Ceph clusters.
   * Default: /var/lib/rook
   *
   * @generated from field: optional string data_dir_host_path = 1;
   */
  dataDirHostPath?: string;

  /**
   * Monitor (MON) daemon configuration.
   *
   * @generated from field: org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephMonSpec mon = 2;
   */
  mon?: CephMonSpec;

  /**
   * Manager (MGR) daemon configuration.
   *
   * @generated from field: org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephMgrSpec mgr = 3;
   */
  mgr?: CephMgrSpec;

  /**
   * Storage configuration for OSDs (Object Storage Daemons).
   *
   * @generated from field: org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephStorageSpec storage = 4;
   */
  storage?: CephStorageSpec;

  /**
   * Resource requests and limits for Ceph daemons.
   *
   * @generated from field: org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephResourcesSpec resources = 5;
   */
  resources?: CephResourcesSpec;

  /**
   * Network configuration for the Ceph cluster.
   *
   * @generated from field: org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephNetworkSpec network = 6;
   */
  network?: CephNetworkSpec;
};

/**
 * Describes the message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephClusterConfig.
 * Use `create(CephClusterConfigSchema)` to create a new message.
 */
export const CephClusterConfigSchema: GenMessage<CephClusterConfig> = /*@__PURE__*/
  messageDesc(file_org_openmcf_provider_kubernetes_kubernetesrookcephcluster_v1_spec, 2);

/**
 * CephMonSpec defines the Ceph Monitor daemon configuration.
 *
 * @generated from message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephMonSpec
 */
export type CephMonSpec = Message<"org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephMonSpec"> & {
  /**
   * Number of monitor daemons to run. Recommended: 3 for high availability.
   * Must be an odd number for proper quorum (1, 3, 5).
   * Default: 3
   *
   * @generated from field: optional int32 count = 1;
   */
  count?: number;

  /**
   * Allow multiple monitors on the same node. Not recommended for production.
   * Default: false
   *
   * @generated from field: optional bool allow_multiple_per_node = 2;
   */
  allowMultiplePerNode?: boolean;
};

/**
 * Describes the message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephMonSpec.
 * Use `create(CephMonSpecSchema)` to create a new message.
 */
export const CephMonSpecSchema: GenMessage<CephMonSpec> = /*@__PURE__*/
  messageDesc(file_org_openmcf_provider_kubernetes_kubernetesrookcephcluster_v1_spec, 3);

/**
 * CephMgrSpec defines the Ceph Manager daemon configuration.
 *
 * @generated from message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephMgrSpec
 */
export type CephMgrSpec = Message<"org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephMgrSpec"> & {
  /**
   * Number of manager daemons to run. Use 2 for high availability.
   * Default: 2
   *
   * @generated from field: optional int32 count = 1;
   */
  count?: number;

  /**
   * Allow multiple managers on the same node.
   * Default: false
   *
   * @generated from field: optional bool allow_multiple_per_node = 2;
   */
  allowMultiplePerNode?: boolean;
};

/**
 * Describes the message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephMgrSpec.
 * Use `create(CephMgrSpecSchema)` to create a new message.
 */
export const CephMgrSpecSchema: GenMessage<CephMgrSpec> = /*@__PURE__*/
  messageDesc(file_org_openmcf_provider_kubernetes_kubernetesrookcephcluster_v1_spec, 4);

/**
 * CephStorageSpec defines how Ceph discovers and uses storage devices.
 *
 * @generated from message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephStorageSpec
 */
export type CephStorageSpec = Message<"org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephStorageSpec"> & {
  /**
   * Use all nodes in the cluster for storage.
   * Default: true
   *
   * @generated from field: optional bool use_all_nodes = 1;
   */
  useAllNodes?: boolean;

  /**
   * Use all devices on each node for storage.
   * Default: true
   *
   * @generated from field: optional bool use_all_devices = 2;
   */
  useAllDevices?: boolean;

  /**
   * Filter devices by name pattern (regex).
   * Example: "^sd[a-z]$" to match sda, sdb, etc.
   *
   * @generated from field: string device_filter = 3;
   */
  deviceFilter: string;

  /**
   * Specific nodes and their storage configuration.
   * Only used when use_all_nodes is false.
   *
   * @generated from field: repeated org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephStorageNodeSpec nodes = 4;
   */
  nodes: CephStorageNodeSpec[];
};

/**
 * Describes the message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephStorageSpec.
 * Use `create(CephStorageSpecSchema)` to create a new message.
 */
export const CephStorageSpecSchema: GenMessage<CephStorageSpec> = /*@__PURE__*/
  messageDesc(file_org_openmcf_provider_kubernetes_kubernetesrookcephcluster_v1_spec, 5);

/**
 * CephStorageNodeSpec defines storage configuration for a specific node.
 *
 * @generated from message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephStorageNodeSpec
 */
export type CephStorageNodeSpec = Message<"org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephStorageNodeSpec"> & {
  /**
   * Node name matching kubernetes.io/hostname label.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Specific devices to use on this node.
   *
   * @generated from field: repeated string devices = 2;
   */
  devices: string[];

  /**
   * Device filter pattern for this node.
   *
   * @generated from field: string device_filter = 3;
   */
  deviceFilter: string;
};

/**
 * Describes the message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephStorageNodeSpec.
 * Use `create(CephStorageNodeSpecSchema)` to create a new message.
 */
export const CephStorageNodeSpecSchema: GenMessage<CephStorageNodeSpec> = /*@__PURE__*/
  messageDesc(file_org_openmcf_provider_kubernetes_kubernetesrookcephcluster_v1_spec, 6);

/**
 * CephNetworkSpec defines network configuration for the Ceph cluster.
 *
 * @generated from message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephNetworkSpec
 */
export type CephNetworkSpec = Message<"org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephNetworkSpec"> & {
  /**
   * Enable encryption for data in transit between Ceph daemons.
   * Requires kernel 5.11+ for full functionality.
   * Default: false
   *
   * @generated from field: optional bool enable_encryption = 1;
   */
  enableEncryption?: boolean;

  /**
   * Enable compression for data in transit.
   * Default: false
   *
   * @generated from field: optional bool enable_compression = 2;
   */
  enableCompression?: boolean;

  /**
   * Require msgr2 protocol (disable legacy msgr v1).
   * Default: false
   *
   * @generated from field: optional bool require_msgr2 = 3;
   */
  requireMsgr2?: boolean;
};

/**
 * Describes the message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephNetworkSpec.
 * Use `create(CephNetworkSpecSchema)` to create a new message.
 */
export const CephNetworkSpecSchema: GenMessage<CephNetworkSpec> = /*@__PURE__*/
  messageDesc(file_org_openmcf_provider_kubernetes_kubernetesrookcephcluster_v1_spec, 7);

/**
 * CephResourcesSpec defines resource allocations for Ceph daemon pods.
 *
 * @generated from message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephResourcesSpec
 */
export type CephResourcesSpec = Message<"org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephResourcesSpec"> & {
  /**
   * Resource allocation for Monitor daemons.
   *
   * @generated from field: org.openmcf.provider.kubernetes.ContainerResources mon = 1;
   */
  mon?: ContainerResources;

  /**
   * Resource allocation for Manager daemons.
   *
   * @generated from field: org.openmcf.provider.kubernetes.ContainerResources mgr = 2;
   */
  mgr?: ContainerResources;

  /**
   * Resource allocation for OSD daemons.
   *
   * @generated from field: org.openmcf.provider.kubernetes.ContainerResources osd = 3;
   */
  osd?: ContainerResources;
};

/**
 * Describes the message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephResourcesSpec.
 * Use `create(CephResourcesSpecSchema)` to create a new message.
 */
export const CephResourcesSpecSchema: GenMessage<CephResourcesSpec> = /*@__PURE__*/
  messageDesc(file_org_openmcf_provider_kubernetes_kubernetesrookcephcluster_v1_spec, 8);

/**
 * CephBlockPoolSpec defines a Ceph block storage pool configuration.
 *
 * @generated from message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephBlockPoolSpec
 */
export type CephBlockPoolSpec = Message<"org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephBlockPoolSpec"> & {
  /**
   * Name of the block pool.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Failure domain for data placement (host, rack, zone, etc).
   * Default: host
   *
   * @generated from field: optional string failure_domain = 2;
   */
  failureDomain?: string;

  /**
   * Number of data replicas.
   * Default: 3
   *
   * @generated from field: optional int32 replicated_size = 3;
   */
  replicatedSize?: number;

  /**
   * StorageClass configuration for this pool.
   *
   * @generated from field: org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephStorageClassSpec storage_class = 4;
   */
  storageClass?: CephStorageClassSpec;
};

/**
 * Describes the message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephBlockPoolSpec.
 * Use `create(CephBlockPoolSpecSchema)` to create a new message.
 */
export const CephBlockPoolSpecSchema: GenMessage<CephBlockPoolSpec> = /*@__PURE__*/
  messageDesc(file_org_openmcf_provider_kubernetes_kubernetesrookcephcluster_v1_spec, 9);

/**
 * CephFilesystemSpec defines a CephFS filesystem configuration.
 *
 * @generated from message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephFilesystemSpec
 */
export type CephFilesystemSpec = Message<"org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephFilesystemSpec"> & {
  /**
   * Name of the filesystem.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Metadata pool replication size.
   * Default: 3
   *
   * @generated from field: optional int32 metadata_pool_replicated_size = 2;
   */
  metadataPoolReplicatedSize?: number;

  /**
   * Data pool replication size.
   * Default: 3
   *
   * @generated from field: optional int32 data_pool_replicated_size = 3;
   */
  dataPoolReplicatedSize?: number;

  /**
   * Failure domain for data placement.
   * Default: host
   *
   * @generated from field: optional string failure_domain = 4;
   */
  failureDomain?: string;

  /**
   * Number of active MDS (Metadata Server) daemons.
   * Default: 1
   *
   * @generated from field: optional int32 active_mds_count = 5;
   */
  activeMdsCount?: number;

  /**
   * Enable active-standby MDS for high availability.
   * Default: true
   *
   * @generated from field: optional bool active_standby = 6;
   */
  activeStandby?: boolean;

  /**
   * Resource allocation for MDS daemons.
   *
   * @generated from field: org.openmcf.provider.kubernetes.ContainerResources mds_resources = 7;
   */
  mdsResources?: ContainerResources;

  /**
   * StorageClass configuration for this filesystem.
   *
   * @generated from field: org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephStorageClassSpec storage_class = 8;
   */
  storageClass?: CephStorageClassSpec;
};

/**
 * Describes the message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephFilesystemSpec.
 * Use `create(CephFilesystemSpecSchema)` to create a new message.
 */
export const CephFilesystemSpecSchema: GenMessage<CephFilesystemSpec> = /*@__PURE__*/
  messageDesc(file_org_openmcf_provider_kubernetes_kubernetesrookcephcluster_v1_spec, 10);

/**
 * CephObjectStoreSpec defines a Ceph object store (RGW) configuration.
 *
 * @generated from message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephObjectStoreSpec
 */
export type CephObjectStoreSpec = Message<"org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephObjectStoreSpec"> & {
  /**
   * Name of the object store.
   *
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * Metadata pool replication size.
   * Default: 3
   *
   * @generated from field: optional int32 metadata_pool_replicated_size = 2;
   */
  metadataPoolReplicatedSize?: number;

  /**
   * Number of erasure coding data chunks for the data pool.
   * Default: 2
   *
   * @generated from field: optional int32 data_pool_erasure_data_chunks = 3;
   */
  dataPoolErasureDataChunks?: number;

  /**
   * Number of erasure coding parity chunks for the data pool.
   * Default: 1
   *
   * @generated from field: optional int32 data_pool_erasure_coding_chunks = 4;
   */
  dataPoolErasureCodingChunks?: number;

  /**
   * Failure domain for data placement.
   * Default: host
   *
   * @generated from field: optional string failure_domain = 5;
   */
  failureDomain?: string;

  /**
   * Preserve pools when the object store is deleted.
   * Default: true
   *
   * @generated from field: optional bool preserve_pools_on_delete = 6;
   */
  preservePoolsOnDelete?: boolean;

  /**
   * Gateway (RGW) port.
   * Default: 80
   *
   * @generated from field: optional int32 gateway_port = 7;
   */
  gatewayPort?: number;

  /**
   * Number of gateway instances.
   * Default: 1
   *
   * @generated from field: optional int32 gateway_instances = 8;
   */
  gatewayInstances?: number;

  /**
   * Resource allocation for gateway pods.
   *
   * @generated from field: org.openmcf.provider.kubernetes.ContainerResources gateway_resources = 9;
   */
  gatewayResources?: ContainerResources;

  /**
   * StorageClass configuration for object bucket claims.
   *
   * @generated from field: org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephStorageClassSpec storage_class = 10;
   */
  storageClass?: CephStorageClassSpec;
};

/**
 * Describes the message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephObjectStoreSpec.
 * Use `create(CephObjectStoreSpecSchema)` to create a new message.
 */
export const CephObjectStoreSpecSchema: GenMessage<CephObjectStoreSpec> = /*@__PURE__*/
  messageDesc(file_org_openmcf_provider_kubernetes_kubernetesrookcephcluster_v1_spec, 11);

/**
 * CephStorageClassSpec defines Kubernetes StorageClass configuration.
 *
 * @generated from message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephStorageClassSpec
 */
export type CephStorageClassSpec = Message<"org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephStorageClassSpec"> & {
  /**
   * Enable creation of a StorageClass for this pool.
   * Default: true
   *
   * @generated from field: optional bool enabled = 1;
   */
  enabled?: boolean;

  /**
   * Name of the StorageClass.
   *
   * @generated from field: string name = 2;
   */
  name: string;

  /**
   * Set as the default StorageClass in the cluster.
   * Default: false
   *
   * @generated from field: optional bool is_default = 3;
   */
  isDefault?: boolean;

  /**
   * Reclaim policy for volumes (Delete or Retain).
   * Default: Delete
   *
   * @generated from field: optional string reclaim_policy = 4;
   */
  reclaimPolicy?: string;

  /**
   * Allow volume expansion after creation.
   * Default: true
   *
   * @generated from field: optional bool allow_volume_expansion = 5;
   */
  allowVolumeExpansion?: boolean;

  /**
   * Volume binding mode (Immediate or WaitForFirstConsumer).
   * Default: Immediate
   *
   * @generated from field: optional string volume_binding_mode = 6;
   */
  volumeBindingMode?: string;
};

/**
 * Describes the message org.openmcf.provider.kubernetes.kubernetesrookcephcluster.v1.CephStorageClassSpec.
 * Use `create(CephStorageClassSpecSchema)` to create a new message.
 */
export const CephStorageClassSpecSchema: GenMessage<CephStorageClassSpec> = /*@__PURE__*/
  messageDesc(file_org_openmcf_provider_kubernetes_kubernetesrookcephcluster_v1_spec, 12);

